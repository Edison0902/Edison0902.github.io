<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">



  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-flash.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="pytorch,One Stage,">





  <link rel="alternate" href="/atom.xml" title="陈家豪的个人博客" type="application/atom+xml">






<meta name="description" content="SSD 目标检测算法 基础知识The Single-Shot MultiBox Detector 两阶段：RCNN（先通过启发式方法或者 CNN 网络（RPN）产生一系列稀疏候选框，然后通过这些框进行分类、回归） 一阶段：YOLO 、RetinaNet 和 SSD （不同位置进行密集抽样，可以采用不同的尺度和长宽比、然后利用CNN提取特征，进行分类与回归）  SSD（参考：https://zhua">
<meta name="keywords" content="pytorch,One Stage">
<meta property="og:type" content="article">
<meta property="og:title" content="SSD 目标检测算法">
<meta property="og:url" content="https://github.com/Edison0902/目标检测/SSD 目标检测算法/index.html">
<meta property="og:site_name" content="陈家豪的个人博客">
<meta property="og:description" content="SSD 目标检测算法 基础知识The Single-Shot MultiBox Detector 两阶段：RCNN（先通过启发式方法或者 CNN 网络（RPN）产生一系列稀疏候选框，然后通过这些框进行分类、回归） 一阶段：YOLO 、RetinaNet 和 SSD （不同位置进行密集抽样，可以采用不同的尺度和长宽比、然后利用CNN提取特征，进行分类与回归）  SSD（参考：https://zhua">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://cdn.nlark.com/yuque/0/2019/png/220248/1551959394881-19541bec-748c-441a-a115-26e91aeb0267.png#align=left&display=inline&height=827&name=image.png&originHeight=827&originWidth=1238&size=856570&status=done&width=1238">
<meta property="og:image" content="https://cdn.nlark.com/yuque/0/2019/svg/220248/1551961674034-1d17488d-4719-4b64-9754-f8b4facedf86.svg#align=left&display=inline&height=19&originHeight=17&originWidth=41&size=0&status=done&width=46">
<meta property="og:image" content="https://cdn.nlark.com/yuque/0/2019/svg/220248/1551961674045-fa2bcb93-0be6-4371-a694-a2a53c2d7293.svg#align=left&display=inline&height=19&originHeight=17&originWidth=41&size=0&status=done&width=46">
<meta property="og:image" content="https://cdn.nlark.com/yuque/0/2019/svg/220248/1551961674488-f2be8c16-030b-4ff0-a804-bead13dce043.svg#align=left&display=inline&height=19&originHeight=17&originWidth=41&size=0&status=done&width=46">
<meta property="og:image" content="https://cdn.nlark.com/yuque/0/2019/svg/220248/1551961674474-6acbf8b8-8c1c-4024-a859-3ce5c541a945.svg#align=left&display=inline&height=19&originHeight=17&originWidth=41&size=0&status=done&width=46">
<meta property="og:image" content="https://cdn.nlark.com/yuque/0/2019/svg/220248/1551961674340-9ea1b7bf-6899-43dd-9752-61c49be022e0.svg#align=left&display=inline&height=19&originHeight=17&originWidth=41&size=0&status=done&width=46">
<meta property="og:image" content="https://cdn.nlark.com/yuque/0/2019/svg/220248/1551961674469-5dd568c0-5374-4647-9b99-e1f97202d5a2.svg#align=left&display=inline&height=19&originHeight=17&originWidth=41&size=0&status=done&width=46">
<meta property="og:image" content="https://cdn.nlark.com/yuque/0/2019/svg/220248/1551961674467-0ac86435-aa12-4dfd-b920-2a1b0562e988.svg#align=left&display=inline&height=19&originHeight=17&originWidth=41&size=0&status=done&width=46">
<meta property="og:image" content="https://cdn.nlark.com/yuque/0/2019/svg/220248/1551961674470-c4760a29-a4be-4a04-a45d-8f75ce534a36.svg#align=left&display=inline&height=19&originHeight=17&originWidth=60&size=0&status=done&width=67">
<meta property="og:image" content="https://cdn.nlark.com/yuque/0/2019/svg/220248/1551961674469-61358401-25a7-476e-9705-48437abcf70d.svg#align=left&display=inline&height=19&originHeight=17&originWidth=41&size=0&status=done&width=46">
<meta property="og:image" content="https://cdn.nlark.com/yuque/0/2019/jpeg/220248/1551962099403-39e8fce3-a0e1-4d44-9ca8-18c266a8ca7a.jpeg#align=left&display=inline&height=256&originHeight=256&originWidth=720&size=0&status=done&width=720">
<meta property="og:image" content="https://cdn.nlark.com/yuque/0/2019/svg/220248/1551962321464-9c2439b1-6ce4-4902-a87b-7279f57b8363.svg#align=left&display=inline&height=19&originHeight=17&originWidth=60&size=0&status=done&width=67">
<meta property="og:image" content="https://cdn.nlark.com/yuque/0/2019/svg/220248/1551962357597-47c17390-4c0f-46d2-a27c-2adafb2d9fba.svg#align=left&display=inline&height=26&originHeight=23&originWidth=345&size=0&status=done&width=388">
<meta property="og:image" content="https://cdn.nlark.com/yuque/0/2019/svg/220248/1551963743239-014b6d6d-1e5f-4cac-8891-b0b64f05631a.svg#align=left&display=inline&height=19&originHeight=17&originWidth=35&size=0&status=done&width=40">
<meta property="og:image" content="https://cdn.nlark.com/yuque/0/2019/png/220248/1551965068101-38563941-551e-4ff5-8509-20a6ff17a457.png#align=left&display=inline&height=468&name=image.png&originHeight=468&originWidth=868&size=360027&status=done&width=868">
<meta property="og:image" content="https://cdn.nlark.com/yuque/0/2019/png/220248/1552297291618-d599aa54-9d38-4d4f-89b4-cc27da7331c8.png#align=left&display=inline&height=861&name=image.png&originHeight=861&originWidth=1285&size=1537680&status=done&width=1285">
<meta property="og:image" content="https://cdn.nlark.com/yuque/0/2019/png/220248/1552286118719-14188821-f153-4a5e-aaa2-16af9d17dab1.png#align=left&display=inline&height=50&name=image.png&originHeight=63&originWidth=380&size=6287&status=done&width=304">
<meta property="og:image" content="https://cdn.nlark.com/yuque/0/2019/png/220248/1552286290859-7204a50e-ac18-48ea-a100-1d957bcf61e6.png#align=left&display=inline&height=29&name=image.png&originHeight=36&originWidth=101&size=1890&status=done&width=81">
<meta property="og:image" content="https://cdn.nlark.com/yuque/0/2019/png/220248/1552286204298-f2724c33-c8e5-4d4e-94db-2abe37206304.png#align=left&display=inline&height=79&name=image.png&originHeight=98&originWidth=122&size=4701&status=done&width=98">
<meta property="og:image" content="https://cdn.nlark.com/yuque/0/2019/png/220248/1552286201202-9a784e6e-45d0-4750-9164-5d1eee31979a.png#align=left&display=inline&height=30&name=image.png&originHeight=38&originWidth=125&size=2225&status=done&width=100">
<meta property="og:image" content="https://cdn.nlark.com/yuque/0/2019/png/220248/1552286204299-ac5644d4-4322-44cf-99df-3d8c5e4247de.png#align=left&display=inline&height=36&name=image.png&originHeight=45&originWidth=113&size=3032&status=done&width=90">
<meta property="og:image" content="https://cdn.nlark.com/yuque/0/2019/png/220248/1552290411114-654137ae-c836-4917-af8e-ec2f3d9592d2.png#align=left&display=inline&height=446&name=image.png&originHeight=557&originWidth=832&size=50994&status=done&width=666">
<meta property="og:image" content="https://cdn.nlark.com/yuque/0/2019/png/220248/1552295800384-c456459f-42d5-4273-a65d-975b49fcc66c.png#align=left&display=inline&height=130&name=image.png&originHeight=163&originWidth=603&size=27643&status=done&width=482">
<meta property="og:updated_time" content="2019-07-09T02:26:02.018Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="SSD 目标检测算法">
<meta name="twitter:description" content="SSD 目标检测算法 基础知识The Single-Shot MultiBox Detector 两阶段：RCNN（先通过启发式方法或者 CNN 网络（RPN）产生一系列稀疏候选框，然后通过这些框进行分类、回归） 一阶段：YOLO 、RetinaNet 和 SSD （不同位置进行密集抽样，可以采用不同的尺度和长宽比、然后利用CNN提取特征，进行分类与回归）  SSD（参考：https://zhua">
<meta name="twitter:image" content="https://cdn.nlark.com/yuque/0/2019/png/220248/1551959394881-19541bec-748c-441a-a115-26e91aeb0267.png#align=left&display=inline&height=827&name=image.png&originHeight=827&originWidth=1238&size=856570&status=done&width=1238">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":true,"scrollpercent":true,"onmobile":true},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://github.com/Edison0902/目标检测/SSD 目标检测算法/">





  <title>SSD 目标检测算法 | 陈家豪的个人博客</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>
    

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">陈家豪的个人博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">记录技术 & 生活</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://github.com/Edison0902/目标检测/SSD 目标检测算法/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jiahao Chen">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/cjh_head_yuque.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="陈家豪的个人博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">SSD 目标检测算法</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-08-18T15:41:18+08:00">
                2017-08-18
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/目标检测/" itemprop="url" rel="index">
                    <span itemprop="name">目标检测</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  9k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  41
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="SSD-目标检测算法"><a href="#SSD-目标检测算法" class="headerlink" title="SSD 目标检测算法"></a>SSD 目标检测算法</h1><p><a name="8453e91e"></a></p>
<h2 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h2><p>The Single-Shot MultiBox Detector</p>
<p>两阶段：RCNN（先通过启发式方法或者 CNN 网络（RPN）产生一系列稀疏候选框，然后通过这些框进行分类、回归）</p>
<p>一阶段：YOLO 、RetinaNet 和 SSD （不同位置进行密集抽样，可以采用不同的尺度和长宽比、然后利用CNN提取特征，进行分类与回归）</p>
<p><img src="https://cdn.nlark.com/yuque/0/2019/png/220248/1551959394881-19541bec-748c-441a-a115-26e91aeb0267.png#align=left&amp;display=inline&amp;height=827&amp;name=image.png&amp;originHeight=827&amp;originWidth=1238&amp;size=856570&amp;status=done&amp;width=1238" alt="image.png"></p>
<p>SSD（参考：<a href="https://zhuanlan.zhihu.com/p/33544892" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/33544892</a>）<br>多框预测<br>相比Yolo，SSD采用CNN来直接进行检测，而不是像Yolo那样在全连接层之后做检测。其实采用卷积直接做检测只是SSD相比Yolo的其中一个不同点，另外还有两个重要的改变，一是SSD提取了不同尺度的特征图来做检测，大尺度特征图（较靠前的特征图）可以用来检测小物体，而小尺度特征图（较靠后的特征图）用来检测大物体；二是SSD采用了不同尺度和长宽比的先验框（Prior boxes, Default boxes，在Faster R-CNN中叫做锚，Anchors）</p>
<p>如果检测目标共有 c 个类别，SSD其实需要预测 c+1 个置信度值，其中第一个置信度指的是不含目标或者属于背景的评分。</p>
<p>在预测过程中，置信度最高的那个类别就是边界框所属的类别</p>
<p>对于一个大小 m* n 的特征图，共有 mn 个单元，每个单元设置的先验框数目记为 k ，那么每个单元共需要 (c+4)k 个预测值，所有的单元共需要 (c+4)kmn 个预测值，由于SSD采用卷积做检测，所以就需要 (c+4)k 个卷积核完成这个特征图的检测过程。</p>
<p>SSD采用VGG16作为基础模型，然后在VGG16的基础上新增了卷积层来获得更多的特征图以用于检测。</p>
<p>采用VGG16做基础模型，首先VGG16是在ILSVRC CLS-LOC数据集预训练。然后借鉴了<a href="http://link.zhihu.com/?target=https%3A//export.arxiv.org/pdf/1606.00915" target="_blank" rel="noopener">DeepLab-LargeFOV</a>，分别将VGG16的全连接层fc6和fc7转换成 <img src="https://cdn.nlark.com/yuque/0/2019/svg/220248/1551961674034-1d17488d-4719-4b64-9754-f8b4facedf86.svg#align=left&amp;display=inline&amp;height=19&amp;originHeight=17&amp;originWidth=41&amp;size=0&amp;status=done&amp;width=46" alt> 卷积层 conv6和 <img src="https://cdn.nlark.com/yuque/0/2019/svg/220248/1551961674045-fa2bcb93-0be6-4371-a694-a2a53c2d7293.svg#align=left&amp;display=inline&amp;height=19&amp;originHeight=17&amp;originWidth=41&amp;size=0&amp;status=done&amp;width=46" alt> 卷积层conv7，同时将池化层pool5由原来的stride=2的 <img src="https://cdn.nlark.com/yuque/0/2019/svg/220248/1551961674488-f2be8c16-030b-4ff0-a804-bead13dce043.svg#align=left&amp;display=inline&amp;height=19&amp;originHeight=17&amp;originWidth=41&amp;size=0&amp;status=done&amp;width=46" alt> 变成stride=1的 <img src="https://cdn.nlark.com/yuque/0/2019/svg/220248/1551961674474-6acbf8b8-8c1c-4024-a859-3ce5c541a945.svg#align=left&amp;display=inline&amp;height=19&amp;originHeight=17&amp;originWidth=41&amp;size=0&amp;status=done&amp;width=46" alt>（猜想是不想reduce特征图大小），为了配合这种变化，采用了一种Atrous Algorithm，其实就是conv6采用扩展卷积或带孔卷积（<a href="http://link.zhihu.com/?target=https%3A//arxiv.org/abs/1511.07122" target="_blank" rel="noopener">Dilation Conv</a>），其在不增加参数与模型复杂度的条件下指数级扩大卷积的视野，其使用扩张率(dilation rate)参数，来表示扩张的大小，如下图6所示，(a)是普通的 <img src="https://cdn.nlark.com/yuque/0/2019/svg/220248/1551961674340-9ea1b7bf-6899-43dd-9752-61c49be022e0.svg#align=left&amp;display=inline&amp;height=19&amp;originHeight=17&amp;originWidth=41&amp;size=0&amp;status=done&amp;width=46" alt> 卷积，其视野就是 <img src="https://cdn.nlark.com/yuque/0/2019/svg/220248/1551961674469-5dd568c0-5374-4647-9b99-e1f97202d5a2.svg#align=left&amp;display=inline&amp;height=19&amp;originHeight=17&amp;originWidth=41&amp;size=0&amp;status=done&amp;width=46" alt> ，(b)是扩张率为1，此时视野变成 <img src="https://cdn.nlark.com/yuque/0/2019/svg/220248/1551961674467-0ac86435-aa12-4dfd-b920-2a1b0562e988.svg#align=left&amp;display=inline&amp;height=19&amp;originHeight=17&amp;originWidth=41&amp;size=0&amp;status=done&amp;width=46" alt> ，(c)扩张率为3时，视野扩大为 <img src="https://cdn.nlark.com/yuque/0/2019/svg/220248/1551961674470-c4760a29-a4be-4a04-a45d-8f75ce534a36.svg#align=left&amp;display=inline&amp;height=19&amp;originHeight=17&amp;originWidth=60&amp;size=0&amp;status=done&amp;width=67" alt> ，但是视野的特征更稀疏了。Conv6采用 <img src="https://cdn.nlark.com/yuque/0/2019/svg/220248/1551961674469-61358401-25a7-476e-9705-48437abcf70d.svg#align=left&amp;display=inline&amp;height=19&amp;originHeight=17&amp;originWidth=41&amp;size=0&amp;status=done&amp;width=46" alt> 大小但dilation rate=6的扩展卷积。</p>
<ol>
<li>将 VGG 的全连接层 fc6、fc7 转换成了 3<em>3 的卷积层 conv6 和 1</em>1 的卷积层 conv7</li>
<li>将池化层 pool5 （stride=2, kernel_size=2）变成了（stride=1, kernel_size=3）</li>
<li>采用 Atrous 算法：扩张率 dilation rate = 6</li>
<li>移除 Dropout 层和 fc8 层，新增一系列卷积层</li>
</ol>
<p><img src="https://cdn.nlark.com/yuque/0/2019/jpeg/220248/1551962099403-39e8fce3-a0e1-4d44-9ca8-18c266a8ca7a.jpeg#align=left&amp;display=inline&amp;height=256&amp;originHeight=256&amp;originWidth=720&amp;size=0&amp;status=done&amp;width=720" alt></p>
<p>其中VGG16中的Conv4_3层将作为用于检测的第一个特征图。conv4_3层特征图大小是 <img src="https://cdn.nlark.com/yuque/0/2019/svg/220248/1551962321464-9c2439b1-6ce4-4902-a87b-7279f57b8363.svg#align=left&amp;display=inline&amp;height=19&amp;originHeight=17&amp;originWidth=60&amp;size=0&amp;status=done&amp;width=67" alt> ，但是该层比较靠前，其norm较大，所以在其后面增加了一个L2 Normalization层（参见<a href="http://link.zhihu.com/?target=https%3A//arxiv.org/abs/1506.04579" target="_blank" rel="noopener">ParseNet</a>），以保证和后面的检测层差异不是很大，这个和Batch Normalization层不太一样，其仅仅是对每个像素点在channle维度做归一化，而Batch Normalization层是在[batch_size, width, height]三个维度上做归一化。归一化后一般设置一个可训练的放缩变量gamma。</p>
<p>从后面新增的卷积层中提取Conv7，Conv8_2，Conv9_2，Conv10_2，Conv11_2作为检测所用的特征图，加上Conv4_3层，共提取了6个特征图，其大小分别是 <img src="https://cdn.nlark.com/yuque/0/2019/svg/220248/1551962357597-47c17390-4c0f-46d2-a27c-2adafb2d9fba.svg#align=left&amp;display=inline&amp;height=26&amp;originHeight=23&amp;originWidth=345&amp;size=0&amp;status=done&amp;width=388" alt> ，但是不同特征图设置的先验框数目不同（同一个特征图上每个单元设置的先验框是相同的，这里的数目指的是一个单元的先验框数目）。先验框的设置，包括尺度（或者说大小）和长宽比两个方面。</p>
<p>先要确定训练图片中的ground truth（真实目标）与哪个先验框来进行匹配，与之匹配的先验框所对应的边界框将负责预测它。在Yolo中，ground truth的中心落在哪个单元格，该单元格中与其IOU最大的边界框负责预测它。但是在SSD中却完全不一样，SSD的先验框与ground truth的匹配原则主要有两点<br>两个原则：</p>
<ol>
<li>对于图片中每个ground truth，找到与其IOU最大的先验框，该先验框与其匹配</li>
<li>对于剩余的未匹配先验框，若某个ground truth的 <img src="https://cdn.nlark.com/yuque/0/2019/svg/220248/1551963743239-014b6d6d-1e5f-4cac-8891-b0b64f05631a.svg#align=left&amp;display=inline&amp;height=19&amp;originHeight=17&amp;originWidth=35&amp;size=0&amp;status=done&amp;width=40" alt> 大于某个阈值（一般是0.5），那么该先验框也与这个ground truth进行匹配</li>
</ol>
<p><a href="http://link.zhihu.com/?target=https%3A//github.com/xiaohu2015/SSD-Tensorflow/blob/master/nets/ssd_common.py" target="_blank" rel="noopener">TensorFlow版本</a>就是只实施了第二个原则，但是这里的<a href="http://link.zhihu.com/?target=https%3A//github.com/amdegroot/ssd.pytorch/blob/master/layers/box_utils.py" target="_blank" rel="noopener">Pytorch</a>两个原则都实施了。图8为一个匹配示意图，其中绿色的GT是ground truth，红色为先验框，FP表示负样本，TP表示正样本。</p>
<p>尽管一个ground truth可以与多个先验框匹配，但是ground truth相对先验框还是太少了，所以负样本相对正样本会很多。为了保证正负样本尽量平衡，SSD采用了hard negative mining，就是对负样本进行抽样，抽样时按照置信度误差（预测背景的置信度越小，误差越大）进行降序排列，选取误差的较大的top-k作为训练的负样本，以保证正负样本比例接近1:3。</p>
<p><img src="https://cdn.nlark.com/yuque/0/2019/png/220248/1551965068101-38563941-551e-4ff5-8509-20a6ff17a457.png#align=left&amp;display=inline&amp;height=468&amp;name=image.png&amp;originHeight=468&amp;originWidth=868&amp;size=360027&amp;status=done&amp;width=868" alt="image.png"></p>
<p>38<em>38 和最后 3</em>3、1*1 对应的先验框为：1:1 两种和 1:2、2:1<br>其他的对应6个先验框：1:1 两种和 1:2、2:1、1:3、3:1</p>
<p><a name="ecf7d7cb"></a></p>
<h2 id="代码结构详解"><a href="#代码结构详解" class="headerlink" title="代码结构详解"></a>代码结构详解</h2><p><img src="https://cdn.nlark.com/yuque/0/2019/png/220248/1552297291618-d599aa54-9d38-4d4f-89b4-cc27da7331c8.png#align=left&amp;display=inline&amp;height=861&amp;name=image.png&amp;originHeight=861&amp;originWidth=1285&amp;size=1537680&amp;status=done&amp;width=1285" alt="image.png"></p>
<hr>
<p><a name="87ce23ba"></a></p>
<h3 id="vgg-修改后的-VGG-16"><a href="#vgg-修改后的-VGG-16" class="headerlink" title="vgg() - 修改后的 VGG-16"></a>vgg() - 修改后的 VGG-16</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">vgg</span><span class="params">(cfg, i, batch_norm=False)</span>:</span></span><br><span class="line">    layers = []</span><br><span class="line">    in_channels = i</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> v <span class="keyword">in</span> cfg:</span><br><span class="line">        <span class="keyword">if</span> v == <span class="string">'M'</span>:</span><br><span class="line">            layers += [nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)]</span><br><span class="line">        <span class="keyword">elif</span> v == <span class="string">'C'</span>:</span><br><span class="line">            layers += [nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, ceil_mode=<span class="literal">True</span>)]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            conv2d = nn.Conv2d(in_channels=in_channels, out_channels=v, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">if</span> batch_norm:</span><br><span class="line">                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=<span class="literal">True</span>)]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                layers += [conv2d, nn.ReLU(inplace=<span class="literal">True</span>)]</span><br><span class="line">            in_channels = v</span><br><span class="line"></span><br><span class="line">            pool5 = nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        conv6 = nn.Conv2d(<span class="number">512</span>, <span class="number">1024</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">6</span>, dilation=<span class="number">6</span>)</span><br><span class="line">        conv7 = nn.Con2d(<span class="number">1024</span>, <span class="number">1024</span>, kernel_size=<span class="number">1</span>)</span><br><span class="line">        layers += [pool5, conv6, nn.ReLU(inplace=<span class="literal">True</span>), conv7, nn.ReLU(inplace=<span class="literal">True</span>)]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> layers</span><br></pre></td></tr></table></figure>
<hr>
<p><a name="29b6837c"></a></p>
<h3 id="add-extras-添加层，作用：回归、分类"><a href="#add-extras-添加层，作用：回归、分类" class="headerlink" title="add_extras() - 添加层，作用：回归、分类"></a>add_extras() - 添加层，作用：回归、分类</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_extras</span><span class="params">(cfg, i,  batch_norm=False)</span>:</span></span><br><span class="line">    exts1_1 = nn.Conv2d(in_channels=i, out_channels=<span class="number">256</span>, kernel_size=<span class="number">1</span>)</span><br><span class="line">    exts1_2 = nn.Conv2d(in_channels=<span class="number">256</span>, out_channels=<span class="number">512</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line">    exts2_1 = nn.Conv2d(<span class="number">512</span>, <span class="number">128</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">    exts2_2 = nn.Conv2d(<span class="number">128</span>, <span class="number">256</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">    exts3_1 = nn.Conv2d(<span class="number">256</span>, <span class="number">128</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">    exts3_2 = nn.Conv2d(<span class="number">128</span>, <span class="number">256</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">    exts4_1 = nn.Conv2d(<span class="number">256</span>, <span class="number">128</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">    exts4_2 = nn.Conv2d(<span class="number">128</span>, <span class="number">256</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> [exts1_1, exts1_2, exts2_1, exts2_2, exts3_1, exts3_2, exts4_1, exts4_2]</span><br></pre></td></tr></table></figure>
<hr>
<p><a name="531450aa"></a></p>
<h3 id="multibox-定义坐标预测层、分类层"><a href="#multibox-定义坐标预测层、分类层" class="headerlink" title="multibox() - 定义坐标预测层、分类层"></a>multibox() - 定义坐标预测层、分类层</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">multibox</span><span class="params">(vgg, extras, num_classes)</span>:</span></span><br><span class="line">    loc_layers = []</span><br><span class="line">    conf_layers = []</span><br><span class="line">    <span class="comment">#vgg_source=[21, -2] # 21 denote conv4_3, -2 denote conv7</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义6个坐标预测层, 输出的通道数就是每个像素点上会产生的 default box 的数量</span></span><br><span class="line">    loc1 = nn.Conv2d(vgg[<span class="number">21</span>].out_channels, <span class="number">4</span>*<span class="number">4</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>) <span class="comment"># 利用conv4_3的特征图谱, 也就是 vgg 网络 List 中的第 21 个元素的输出(注意不是第21层, 因为这中间还包含了不带参数的池化层).</span></span><br><span class="line">    loc2 = nn.Conv2d(vgg[<span class="number">-2</span>].out_channels, <span class="number">6</span>*<span class="number">4</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>) <span class="comment"># Conv7</span></span><br><span class="line">    loc3 = nn.Conv2d(vgg[<span class="number">1</span>].out_channels, <span class="number">6</span>*<span class="number">4</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>) <span class="comment"># exts1_2</span></span><br><span class="line">    loc4 = nn.Conv2d(extras[<span class="number">3</span>].out_channels, <span class="number">6</span>*<span class="number">4</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>) <span class="comment"># exts2_2</span></span><br><span class="line">    loc5 = nn.Conv2d(extras[<span class="number">5</span>].out_channels, <span class="number">4</span>*<span class="number">4</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>) <span class="comment"># exts3_2</span></span><br><span class="line">    loc6 = nn.Conv2d(extras[<span class="number">7</span>].out_channels, <span class="number">4</span>*<span class="number">4</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>) <span class="comment"># exts4_2</span></span><br><span class="line">    loc_layers = [loc1, loc2, loc3, loc4, loc5, loc6]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义分类层, 和定位层差不多, 只不过输出的通道数不一样, 因为对于每一个像素点上的每一个default box,</span></span><br><span class="line">    <span class="comment"># 都需要预测出属于任意一个类的概率, 因此通道数为 default box 的数量乘以类别数.</span></span><br><span class="line">    conf1 = nn.Conv2d(vgg[<span class="number">21</span>].out_channels, <span class="number">4</span>*num_classes, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">    conf2 = nn.Conv2d(vgg[<span class="number">-2</span>].out_channels, <span class="number">6</span>*num_classes, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">    conf3 = nn.Conv2d(extras[<span class="number">1</span>].out_channels, <span class="number">6</span>*num_classes, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">    conf4 = nn.Conv2d(extras[<span class="number">3</span>].out_channels, <span class="number">6</span>*num_classes, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">    conf5 = nn.Conv2d(extras[<span class="number">5</span>].out_channels, <span class="number">4</span>*num_classes, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">    conf6 = nn.Conv2d(extras[<span class="number">7</span>].out_channels, <span class="number">4</span>*num_classes, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">    conf_layers = [conf1, conf2, conf3, conf4, conf5, conf6]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># loc_layers: [b×w1×h1×4*4, b×w2×h2×6*4, b×w3×h3×6*4, b×w4×h4×6*4, b×w5×h5×4*4, b×w6×h6×4*4]</span></span><br><span class="line">    <span class="comment"># conf_layers: [b×w1×h1×4*C, b×w2×h2×6*C, b×w3×h3×6*C, b×w4×h4×6*C, b×w5×h5×4*C, b×w6×h6×4*C] C为num_classes</span></span><br><span class="line">    <span class="comment"># 注意pytorch中卷积层的输入输出维度是:[N×C×H×W], 上面的顺序有点错误, 不过改起来太麻烦</span></span><br><span class="line">    <span class="keyword">return</span> loc_layers, conf_layers</span><br></pre></td></tr></table></figure>
<hr>
<p><a name="176e10c2"></a></p>
<h3 id="SSD-网络定义"><a href="#SSD-网络定义" class="headerlink" title="SSD 网络定义"></a>SSD 网络定义</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ssd.py</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SSD</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="comment"># SSD网络是由 VGG 网络后接 multibox 卷积层 组成的, 每一个 multibox 层会有如下分支:</span></span><br><span class="line">    <span class="comment"># - 用于class conf scores的卷积层</span></span><br><span class="line">    <span class="comment"># - 用于localization predictions的卷积层</span></span><br><span class="line">    <span class="comment"># - 与priorbox layer相关联, 产生默认的bounding box</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 参数:</span></span><br><span class="line">    <span class="comment"># phase: test/train</span></span><br><span class="line">    <span class="comment"># size: 输入图片的尺寸</span></span><br><span class="line">    <span class="comment"># base: VGG16的层</span></span><br><span class="line">    <span class="comment"># extras: 将输出结果送到multibox loc和conf layers的额外的层</span></span><br><span class="line">    <span class="comment"># head: "multibox head", 包含一系列的loc和conf卷积层.</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, phase, size, base, extras, head, num_classes)</span>:</span></span><br><span class="line">        <span class="comment"># super(SSD, self) 首先找到 SSD 的父类, 然后把类SSD的对象转换为父类的对象</span></span><br><span class="line">        super(SSD, self).__init__()</span><br><span class="line">        self.phase = phase</span><br><span class="line">        self.num_classes = num_classes</span><br><span class="line">        self.cfg = (coco, voc)[num_classes == <span class="number">21</span>]</span><br><span class="line">        self.priorbox = PriorBox(self.cfg) <span class="comment"># layers/functions/prior_box.py class PriorBox(object)</span></span><br><span class="line">        self.priors = Variable(self.priorbox.forward(), volatile=<span class="literal">True</span>) <span class="comment"># from torch.autograd import Variable</span></span><br><span class="line">        self.size = size</span><br><span class="line"></span><br><span class="line">        self.vgg = nn.ModuleList(base)</span><br><span class="line">        self.L2Norm = L2Norm(<span class="number">512</span>,<span class="number">20</span>)  <span class="comment"># layers/modules/l2norm.py class L2Norm(nn.Module)</span></span><br><span class="line">        self.extras = nn.ModuleList(extras)</span><br><span class="line"></span><br><span class="line">        self.loc = nn.ModuleList(head[<span class="number">0</span>]) <span class="comment"># head = (loc_layers, conf_layers)</span></span><br><span class="line">        self.conf = nn.ModuleList(head[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> phase = <span class="string">"test"</span>:</span><br><span class="line">            self.softmax = nn.Softmax(dim=<span class="number">-1</span>) <span class="comment"># 用于囧穿概率</span></span><br><span class="line">            self.detect = Detect(num_classes, <span class="number">0</span>, <span class="number">200</span>, <span class="number">0.01</span>, <span class="number">0.45</span>) <span class="comment">#  layers/functions/detection.py class Detect</span></span><br><span class="line">            <span class="comment"># 用于将预测结果转换成对应的坐标和类别编号形式, 方便可视化.</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="comment"># 定义forward函数, 将设计好的layers和ops应用到输入图片 x 上</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 参数: x, 输入的batch 图片, Shape: [batch, 3, 300, 300]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 返回值: 取决于不同阶段</span></span><br><span class="line">        <span class="comment"># test: 预测的类别标签, confidence score, 以及相关的location.</span></span><br><span class="line">        <span class="comment">#       Shape: [batch, topk, 7]</span></span><br><span class="line">        <span class="comment"># train: 关于以下输出的元素组成的列表</span></span><br><span class="line">        <span class="comment">#       1: confidence layers, Shape: [batch*num_priors, num_classes]</span></span><br><span class="line">        <span class="comment">#       2: localization layers, Shape: [batch, num_priors*4]</span></span><br><span class="line">        <span class="comment">#       3: priorbox layers, Shape: [2, num_priors*4]</span></span><br><span class="line">        sources = list() <span class="comment"># 这个列表存储的是参与预测的卷积层的输出, 也就是原文中那6个指定的卷积层</span></span><br><span class="line">        loc = list() <span class="comment"># 用于存储预测的边框信息</span></span><br><span class="line">        conf = list() <span class="comment"># 用于存储预测的类别信息</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算vgg直到conv4_3的relu</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">23</span>):</span><br><span class="line">            x = self.vgg[k](x)</span><br><span class="line"></span><br><span class="line">        s = self.L2Norm(x)</span><br><span class="line">        sources.append(s) <span class="comment"># 将 conv4_3 的特征层输出添加到 sources 中, 后面会根据 sources 中的元素进行预测</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将vgg应用到fc7</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">23</span>, len(self.vgg)):</span><br><span class="line">            x = self.vgg[k](x)</span><br><span class="line">        sources.append(x) <span class="comment"># 同理, 添加到 sources 列表中</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算extras layers, 并且将结果存储到sources列表中</span></span><br><span class="line">        <span class="keyword">for</span> k, v <span class="keyword">in</span> enumerate(self.extras):</span><br><span class="line">            x = F.relu(v(x), inplace=<span class="literal">True</span>) <span class="comment"># import torch.nn.functional as F</span></span><br><span class="line">            <span class="keyword">if</span> k % <span class="number">2</span> = <span class="number">1</span>: <span class="comment"># 在extras_layers中, 第1,3,5,7,9(从第0开始)的卷积层的输出会用于预测box位置和类别, 因此, 将其添加到 sources列表中</span></span><br><span class="line">                sources.append(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 应用multibox到source layers上, source layers中的元素均为各个用于预测的特征图谱</span></span><br><span class="line">        <span class="comment"># apply multibox to source layers</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 注意pytorch中卷积层的输入输出维度是:[N×C×H×W]</span></span><br><span class="line">        <span class="keyword">for</span> (x, l, c) <span class="keyword">in</span> zip(sources, self.loc, self.conf):</span><br><span class="line">            <span class="comment"># permute重新排列维度顺序, PyTorch维度的默认排列顺序为 (N, C, H, W),</span></span><br><span class="line">            <span class="comment"># 因此, 这里的排列是将其改为 $(N, H, W, C)$.</span></span><br><span class="line">            <span class="comment"># contiguous返回内存连续的tensor, 由于在执行permute或者transpose等操作之后, tensor的内存地址可能不是连续的,</span></span><br><span class="line">            <span class="comment"># 然后 view 操作是基于连续地址的, 因此, 需要调用contiguous语句.</span></span><br><span class="line">            loc.append(l(x).permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>).contiguous())</span><br><span class="line">            conf.append(c(x).permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>).contiguous())</span><br><span class="line">            <span class="comment"># loc: [b×w1×h1×4*4, b×w2×h2×6*4, b×w3×h3×6*4, b×w4×h4×6*4, b×w5×h5×4*4, b×w6×h6×4*4]</span></span><br><span class="line">            <span class="comment"># conf: [b×w1×h1×4*C, b×w2×h2×6*C, b×w3×h3×6*C, b×w4×h4×6*C, b×w5×h5×4*C, b×w6×h6×4*C] C为num_classes</span></span><br><span class="line">        <span class="comment"># cat 是 concatenate 的缩写, view返回一个新的tensor, 具有相同的数据但是不同的size, 类似于numpy的reshape</span></span><br><span class="line">        <span class="comment"># 在调用view之前, 需要先调用contiguous</span></span><br><span class="line">        loc = torch.cat([o.view(o.size(<span class="number">0</span>), <span class="number">-1</span>) <span class="keyword">for</span> o <span class="keyword">in</span> loc], <span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 将除batch以外的其他维度合并, 因此, 对于边框坐标来说, 最终的shape为(两维):[batch, num_boxes*4]</span></span><br><span class="line">        conf = torch.cat([o.view(o.size(<span class="number">0</span>), <span class="number">-1</span>) <span class="keyword">for</span> o <span class="keyword">in</span> conf], <span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 同理, 最终的shape为(两维):[batch, num_boxes*num_classes]</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.phase == <span class="string">"test"</span>:</span><br><span class="line">            <span class="comment"># 这里用到了 detect 对象, 该对象主要由于接预测出来的结果进行解析, 以获得方便可视化的边框坐标和类别编号, 具体实现会在后文讨论.</span></span><br><span class="line">            output = self.detect(</span><br><span class="line">                loc.view(loc.size(<span class="number">0</span>), <span class="number">-1</span>, <span class="number">4</span>), <span class="comment">#  又将shape转换成: [batch, num_boxes, 4], 即[1, 8732, 4]</span></span><br><span class="line">                self.softmax(conf.view(conf.size(<span class="number">0</span>), <span class="number">-1</span>, self.num_classes)), <span class="comment"># 同理,  shape 为[batch, num_boxes, num_classes], 即 [1, 8732, 21]</span></span><br><span class="line">                self.priors.type(type(x.data))</span><br><span class="line">                <span class="comment"># 利用 PriorBox对象获取特征图谱上的 default box, 该参数的shape为: [8732,4]. 关于生成 default box 的方法实际上很简单, 类似于 anchor box, 详细的代码实现会在后文解析.</span></span><br><span class="line">                <span class="comment"># 这里的 self.priors.type(type(x.data)) 与 self.priors 就结果而言完全等价(自己试验过了), 但是为什么?</span></span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">if</span> self.phase == <span class="string">"train"</span>: <span class="comment"># 如果是训练阶段, 则无需解析预测结果, 直接返回然后求损失.</span></span><br><span class="line">            output = (</span><br><span class="line">                loc.view(loc.size(<span class="number">0</span>), <span class="number">-1</span>, <span class="number">4</span>), conf.view(conf.size(<span class="number">0</span>), <span class="number">-1</span>, self.num_classes), self.priors</span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">load_weights</span><span class="params">(self, base_file)</span>:</span> <span class="comment"># 加载权重文件</span></span><br><span class="line">        other, ext = os.path.splitext(base_file)</span><br><span class="line">        <span class="keyword">if</span> ext == <span class="string">".pkl"</span> <span class="keyword">or</span> <span class="string">".pth"</span>:</span><br><span class="line">            print(<span class="string">"Loading weights into state dict..."</span>)</span><br><span class="line">            self.load_state_dict(torch.load(base_file, map_location=<span class="keyword">lambda</span> storage, loc: storage))</span><br><span class="line">            print(<span class="string">"Finished!"</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            print(<span class="string">"Sorry only .pth and .pkl files supported"</span>)</span><br></pre></td></tr></table></figure>
<p><a name="ed03f0da"></a></p>
<h4 id="（一）PriorBox-类-用于生成-Default-box"><a href="#（一）PriorBox-类-用于生成-Default-box" class="headerlink" title="（一）PriorBox 类 - 用于生成 Default box"></a>（一）PriorBox 类 - 用于生成 Default box</h4><p>layers/functions/prior_box.py<br>(也可以看成是 anchor box) </p>
<p>根据 SSD 的原理, 需要在选定的特征图谱上输出 Default Box, 然后根据这些 Default Box 进行边框回归任务. 首先梳理一下生成 Default Box 的思路. 假如feature maps数量为 m, 那么每一个feature map中的default box的尺寸大小计算如下:<br><img src="https://cdn.nlark.com/yuque/0/2019/png/220248/1552286118719-14188821-f153-4a5e-aaa2-16af9d17dab1.png#align=left&amp;display=inline&amp;height=50&amp;name=image.png&amp;originHeight=63&amp;originWidth=380&amp;size=6287&amp;status=done&amp;width=304" alt="image.png"><br>上式中, Smin=0.2, Smax=0.9. 对于原文中的设置 m=6(4,6,6,6,4,4), 因此就有 :<br>s={0.2,0.34,0.48,0.62,0.76,0.9}<br>然后, 几个不同的aspect ratio, 用 arar 表示: ar=1,2,3,1/2,1/3, 则每一个default boxes 的width 和height就可以得到(<img src="https://cdn.nlark.com/yuque/0/2019/png/220248/1552286290859-7204a50e-ac18-48ea-a100-1d957bcf61e6.png#align=left&amp;display=inline&amp;height=29&amp;name=image.png&amp;originHeight=36&amp;originWidth=101&amp;size=1890&amp;status=done&amp;width=81" alt="image.png"> ):<br><img src="https://cdn.nlark.com/yuque/0/2019/png/220248/1552286204298-f2724c33-c8e5-4d4e-94db-2abe37206304.png#align=left&amp;display=inline&amp;height=79&amp;name=image.png&amp;originHeight=98&amp;originWidth=122&amp;size=4701&amp;status=done&amp;width=98" alt="image.png"><br>对于宽高比为1的 default box, 我们额外添加了一个 scale 为 <img src="https://cdn.nlark.com/yuque/0/2019/png/220248/1552286201202-9a784e6e-45d0-4750-9164-5d1eee31979a.png#align=left&amp;display=inline&amp;height=30&amp;name=image.png&amp;originHeight=38&amp;originWidth=125&amp;size=2225&amp;status=done&amp;width=100" alt="image.png"> 的 box, 因此 feature map 上的每一个像素点都对应着6个 default boxes (<strong>per feature map localtion</strong>).<br>每一个default box的中心, 设置为: <img src="https://cdn.nlark.com/yuque/0/2019/png/220248/1552286204299-ac5644d4-4322-44cf-99df-3d8c5e4247de.png#align=left&amp;display=inline&amp;height=36&amp;name=image.png&amp;originHeight=45&amp;originWidth=113&amp;size=3032&amp;status=done&amp;width=90" alt="image.png">, 其中, |fk| 是第 k 个feature map的大小 i,j对应了 feature map 上所有可能的像素点.<br><strong>在实际使用中, 可以自己根据数据集的特点来安排不同的 default boxes 参数组合</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> division</span><br><span class="line"><span class="keyword">from</span> math <span class="keyword">import</span> sqrt <span class="keyword">as</span> sqrt</span><br><span class="line"><span class="keyword">from</span> itertools <span class="keyword">import</span> product <span class="keyword">as</span> product</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment"># Default-Box 生成候选框</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PriorBox</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">"""Compute priorbox coordinates in center-offset form for each source</span></span><br><span class="line"><span class="string">    feature map.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># 所谓 prior-box 实际上就是网格中每一个 cell 推荐的 box</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, cfg)</span>:</span></span><br><span class="line">        <span class="comment"># 在 SSD 的 init 中, cfg=(coco, voc)[num_classes=21]</span></span><br><span class="line">        <span class="comment"># coco, voc 的相关配置都来自于 data/cfg.py 文件</span></span><br><span class="line"></span><br><span class="line">        super(PriorBox, self).__init__()</span><br><span class="line">        self.image_size = cfg[<span class="string">'min_dim'</span>]		<span class="comment"># 300</span></span><br><span class="line">        <span class="comment"># number of priors for feature map location (either 4 or 6)</span></span><br><span class="line">        self.num_priors = len(cfg[<span class="string">'aspect_ratios'</span>]) 	<span class="comment"># [[2], [2, 3], [2, 3], [2, 3], [2], [2]]</span></span><br><span class="line">        self.variance = cfg[<span class="string">'variance'</span>] <span class="keyword">or</span> [<span class="number">0.1</span>]		<span class="comment"># [0.1, 0.2]</span></span><br><span class="line">        self.feature_maps = cfg[<span class="string">'feature_maps'</span>]		<span class="comment"># [38, 19, 10, 5, 3, 1]</span></span><br><span class="line">        self.min_sizes = cfg[<span class="string">'min_sizes'</span>]		<span class="comment"># [21, 45, 99, 153, 207, 261]</span></span><br><span class="line">        self.max_sizes = cfg[<span class="string">'max_sizes'</span>]		<span class="comment"># [45, 99, 153, 207, 261, 315]</span></span><br><span class="line">        self.steps = cfg[<span class="string">'steps'</span>]		<span class="comment"># [8, 16, 32, 64, 100, 300]</span></span><br><span class="line">        self.aspect_ratios = cfg[<span class="string">'aspect_ratios'</span>]		<span class="comment">#</span></span><br><span class="line">        self.clip = cfg[<span class="string">'clip'</span>]		<span class="comment"># True</span></span><br><span class="line">        self.version = cfg[<span class="string">'name'</span>]		<span class="comment"># 'COCO'</span></span><br><span class="line">        <span class="keyword">for</span> v <span class="keyword">in</span> self.variance:</span><br><span class="line">            <span class="keyword">if</span> v &lt;= <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">raise</span> ValueError(<span class="string">'Variances must be greater than 0'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self)</span>:</span></span><br><span class="line">        mean = []</span><br><span class="line">        <span class="keyword">for</span> k, f <span class="keyword">in</span> enumerate(self.feature_maps):               <span class="comment"># 存放的是feature map的尺寸:38,19,10,5,3,1</span></span><br><span class="line">            <span class="comment"># from itertools import product as product</span></span><br><span class="line">            <span class="comment"># product 用于求多个可迭代对象的笛卡尔积</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> i, j <span class="keyword">in</span> product(range(f), repeat=<span class="number">2</span>):</span><br><span class="line">                <span class="comment"># 这里实际上可以用最普通的for循环嵌套来代替, 主要目的是产生anchor的坐标(i,j)</span></span><br><span class="line">								<span class="comment"># product 用于求多个可迭代对象的笛卡尔积</span></span><br><span class="line">                </span><br><span class="line">                f_k = self.image_size / self.steps[k]           <span class="comment"># steps=[8,16,32,64,100,300]. f_k大约为feature map的尺寸</span></span><br><span class="line"></span><br><span class="line">                <span class="comment"># unit center x,y</span></span><br><span class="line">                <span class="comment"># 求得center的坐标, 浮点类型. 实际上, 这里也可以直接使用整数类型的 `f`, 计算上没太大差别</span></span><br><span class="line">                cx = (j + <span class="number">0.5</span>) / f_k</span><br><span class="line">                cy = (i + <span class="number">0.5</span>) / f_k</span><br><span class="line"></span><br><span class="line">                <span class="comment"># aspect_ratio: 1</span></span><br><span class="line">                <span class="comment"># rel size: min_size</span></span><br><span class="line">                <span class="comment"># aspect_ratios 为1时对应的box</span></span><br><span class="line">                s_k = self.min_sizes[k]/self.image_size</span><br><span class="line">                mean += [cx, cy, s_k, s_k]</span><br><span class="line"></span><br><span class="line">                <span class="comment"># aspect_ratio: 1</span></span><br><span class="line">                <span class="comment"># rel size: sqrt(s_k * s_(k+1))</span></span><br><span class="line">                <span class="comment"># 根据原文, 当 aspect_ratios 为1时, 会有一个额外的 box, 如下:</span></span><br><span class="line">                s_k_prime = sqrt(s_k * (self.max_sizes[k]/self.image_size))</span><br><span class="line">                mean += [cx, cy, s_k_prime, s_k_prime]</span><br><span class="line"></span><br><span class="line">                <span class="comment"># rest of aspect ratios</span></span><br><span class="line">                <span class="comment"># 其余(2, 或 2,3)的宽高比(aspect ratio)</span></span><br><span class="line">                <span class="keyword">for</span> ar <span class="keyword">in</span> self.aspect_ratios[k]:</span><br><span class="line">                    mean += [cx, cy, s_k*sqrt(ar), s_k/sqrt(ar)]</span><br><span class="line">                    mean += [cx, cy, s_k/sqrt(ar), s_k*sqrt(ar)]</span><br><span class="line">                <span class="comment"># 综上, 每个卷积特征图谱上每个像素点最终产生的 box 数量要么为4, 要么为6, 根据不同情况可自行修改.</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># back to torch land</span></span><br><span class="line">        output = torch.Tensor(mean).view(<span class="number">-1</span>, <span class="number">4</span>)</span><br><span class="line">        <span class="keyword">if</span> self.clip:</span><br><span class="line">            output.clamp_(max=<span class="number">1</span>, min=<span class="number">0</span>)                         <span class="comment"># clamp_ 是clamp的原地执行版本</span></span><br><span class="line">        <span class="keyword">return</span> output                                           <span class="comment"># 输出default box坐标(可以理解为anchor box)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># 最终, 输出的 ouput 就是一张图片中所有的 default box 的坐标, 对于论文中的默认设置来说产生的 box 数量为: 8732</span></span><br></pre></td></tr></table></figure>
<p><strong>上面用到了 python 自带的迭代器 itertools。</strong><br><a href="http://funhacks.net/2017/02/13/itertools/" target="_blank" rel="noopener">http://funhacks.net/2017/02/13/itertools/</a></p>
<p>迭代器的特点是：惰性求值（Lazy evaluation），即只有当迭代至某个值时，它才会被计算，这个特点使得迭代器特别适合于遍历大文件或无限集合等，因为我们不用一次性将它们存储在内存中。</p>
<p><code>product</code> 用于求多个可迭代对象的笛卡尔积，它跟嵌套的 for 循环等价。它的一般使用形式如下：<br>（其中，<strong>repeat</strong> 是一个关键字参数，用于指定重复生成序列的次数）                                              </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">product(iter1, iter2, ... iterN, [repeat=<span class="number">1</span>])</span><br></pre></td></tr></table></figure>
<p><strong>关于 enumerate() 函数</strong><br><strong><br><img src="https://cdn.nlark.com/yuque/0/2019/png/220248/1552290411114-654137ae-c836-4917-af8e-ec2f3d9592d2.png#align=left&amp;display=inline&amp;height=446&amp;name=image.png&amp;originHeight=557&amp;originWidth=832&amp;size=50994&amp;status=done&amp;width=666" alt="image.png"></strong></p>
<hr>
<p><a name="8d78de55"></a></p>
<h4 id="（二）L2Norm-类-实现了-L2归一化"><a href="#（二）L2Norm-类-实现了-L2归一化" class="headerlink" title="（二）L2Norm 类 - 实现了 L2归一化"></a>（二）L2Norm 类 - 实现了 L2归一化</h4><p>layers/modules/l2norm.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Function</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">import</span> torch.nn.init <span class="keyword">as</span> init</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">L2Norm</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,n_channels, scale)</span>:</span></span><br><span class="line">        super(L2Norm,self).__init__()</span><br><span class="line">        self.n_channels = n_channels</span><br><span class="line">        self.gamma = scale <span class="keyword">or</span> <span class="literal">None</span></span><br><span class="line">        self.eps = <span class="number">1e-10</span></span><br><span class="line">        self.weight = nn.Parameter(torch.Tensor(self.n_channels))</span><br><span class="line">        self.reset_parameters()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reset_parameters</span><span class="params">(self)</span>:</span></span><br><span class="line">        init.constant(self.weight,self.gamma)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        norm = x.pow(<span class="number">2</span>).sum(dim=<span class="number">1</span>, keepdim=<span class="literal">True</span>).sqrt()+self.eps</span><br><span class="line">        <span class="comment">#x /= norm</span></span><br><span class="line">        x = torch.div(x,norm)</span><br><span class="line">        out = self.weight.unsqueeze(<span class="number">0</span>).unsqueeze(<span class="number">2</span>).unsqueeze(<span class="number">3</span>).expand_as(x) * x</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>
<p><a name="c35b6b13"></a></p>
<h4 id="（三）Detect-类-用于解析预测结果-并将其转换成边框坐标和类别编号"><a href="#（三）Detect-类-用于解析预测结果-并将其转换成边框坐标和类别编号" class="headerlink" title="（三）Detect 类 - 用于解析预测结果, 并将其转换成边框坐标和类别编号"></a>（三）Detect 类 - 用于解析预测结果, 并将其转换成边框坐标和类别编号</h4><p>layers/functions/detection.py<br>在模型中, 我们为了加快训练速度, 促使模型收敛, 因此会将相应的 box 的坐标转换成与图片size成比例的小数形式, 因此, 无法直接将模型产生的预测结果可视化.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Function</span><br><span class="line"><span class="keyword">from</span> SSD.layers.box_utils <span class="keyword">import</span> decode, nms</span><br><span class="line"><span class="keyword">from</span> SSD.data <span class="keyword">import</span> voc0712 <span class="keyword">as</span> cfg</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Detect</span><span class="params">(Function)</span>:</span></span><br><span class="line">    <span class="string">"""At test time, Detect is the final layer of SSD.  Decode location preds,</span></span><br><span class="line"><span class="string">    apply non-maximum suppression to location predictions based on conf</span></span><br><span class="line"><span class="string">    scores and threshold to a top_k number of output predictions for both</span></span><br><span class="line"><span class="string">    confidence score and locations.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, num_classes, bkg_label, top_k, conf_thresh, nms_thresh)</span>:</span></span><br><span class="line">        self.num_classes = num_classes</span><br><span class="line">        self.background_label = bkg_label</span><br><span class="line">        self.top_k = top_k</span><br><span class="line">        <span class="comment"># Parameters used in nms.</span></span><br><span class="line">        self.nms_thresh = nms_thresh</span><br><span class="line">        <span class="keyword">if</span> nms_thresh &lt;= <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">'nms_threshold must be non negative.'</span>)</span><br><span class="line">        self.conf_thresh = conf_thresh</span><br><span class="line">        self.variance = cfg[<span class="string">'variance'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, loc_data, conf_data, prior_data)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            loc_data: (tensor) Loc preds from loc layers</span></span><br><span class="line"><span class="string">                Shape: [batch,num_priors*4]</span></span><br><span class="line"><span class="string">            conf_data: (tensor) Shape: Conf preds from conf layers</span></span><br><span class="line"><span class="string">                Shape: [batch*num_priors,num_classes]</span></span><br><span class="line"><span class="string">            prior_data: (tensor) Prior boxes and variances from priorbox layers</span></span><br><span class="line"><span class="string">                Shape: [1,num_priors,4]</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        num = loc_data.size(<span class="number">0</span>)  <span class="comment"># batch size</span></span><br><span class="line">        num_priors = prior_data.size(<span class="number">0</span>)</span><br><span class="line">        output = torch.zeros(num, self.num_classes, self.top_k, <span class="number">5</span>)</span><br><span class="line">        conf_preds = conf_data.view(num, num_priors,</span><br><span class="line">                                    self.num_classes).transpose(<span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Decode predictions into bboxes.</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(num):</span><br><span class="line">            decoded_boxes = decode(loc_data[i], prior_data, self.variance)</span><br><span class="line">            <span class="comment"># For each class, perform nms</span></span><br><span class="line">            conf_scores = conf_preds[i].clone()</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> cl <span class="keyword">in</span> range(<span class="number">1</span>, self.num_classes):</span><br><span class="line">                c_mask = conf_scores[cl].gt(self.conf_thresh)</span><br><span class="line">                scores = conf_scores[cl][c_mask]</span><br><span class="line">                <span class="keyword">if</span> scores.dim() == <span class="number">0</span>:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                l_mask = c_mask.unsqueeze(<span class="number">1</span>).expand_as(decoded_boxes)</span><br><span class="line">                boxes = decoded_boxes[l_mask].view(<span class="number">-1</span>, <span class="number">4</span>)</span><br><span class="line">                <span class="comment"># idx of highest scoring and non-overlapping boxes per class</span></span><br><span class="line">                ids, count = nms(boxes, scores, self.nms_thresh, self.top_k)</span><br><span class="line">                output[i, cl, :count] = \</span><br><span class="line">                    torch.cat((scores[ids[:count]].unsqueeze(<span class="number">1</span>),</span><br><span class="line">                               boxes[ids[:count]]), <span class="number">1</span>)</span><br><span class="line">        flt = output.contiguous().view(num, <span class="number">-1</span>, <span class="number">5</span>)</span><br><span class="line">        _, idx = flt[:, :, <span class="number">0</span>].sort(<span class="number">1</span>, descending=<span class="literal">True</span>)</span><br><span class="line">        _, rank = idx.sort(<span class="number">1</span>)</span><br><span class="line">        flt[(rank &lt; self.top_k).unsqueeze(<span class="number">-1</span>).expand_as(flt)].fill_(<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>
<p><a name="e183a27b"></a></p>
<h4 id="decode-和-nms-函数"><a href="#decode-和-nms-函数" class="headerlink" title="decode() 和 nms() 函数"></a>decode() 和 nms() 函数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">decode</span><span class="params">(loc, priors, variances)</span>:</span></span><br><span class="line">    <span class="string">"""Decode locations from predictions using priors to undo</span></span><br><span class="line"><span class="string">    the encoding we did for offset regression at train time.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        loc (tensor): location predictions for loc layers,</span></span><br><span class="line"><span class="string">            Shape: [num_priors,4]</span></span><br><span class="line"><span class="string">        priors (tensor): Prior boxes in center-offset form.</span></span><br><span class="line"><span class="string">            Shape: [num_priors,4].</span></span><br><span class="line"><span class="string">        variances: (list[float]) Variances of priorboxes</span></span><br><span class="line"><span class="string">    Return:</span></span><br><span class="line"><span class="string">        decoded bounding box predictions</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    boxes = torch.cat((</span><br><span class="line">        priors[:, :<span class="number">2</span>] + loc[:, :<span class="number">2</span>] * variances[<span class="number">0</span>] * priors[:, <span class="number">2</span>:],</span><br><span class="line">        priors[:, <span class="number">2</span>:] * torch.exp(loc[:, <span class="number">2</span>:] * variances[<span class="number">1</span>])), <span class="number">1</span>)</span><br><span class="line">    boxes[:, :<span class="number">2</span>] -= boxes[:, <span class="number">2</span>:] / <span class="number">2</span></span><br><span class="line">    boxes[:, <span class="number">2</span>:] += boxes[:, :<span class="number">2</span>]</span><br><span class="line">    <span class="keyword">return</span> boxes</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">nms</span><span class="params">(boxes, scores, overlap=<span class="number">0.5</span>, top_k=<span class="number">200</span>)</span>:</span></span><br><span class="line">    <span class="string">"""Apply non-maximum suppression at test time to avoid detecting too many</span></span><br><span class="line"><span class="string">    overlapping bounding boxes for a given object.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        boxes: (tensor) The location preds for the img, Shape: [num_priors,4].</span></span><br><span class="line"><span class="string">        scores: (tensor) The class predscores for the img, Shape:[num_priors].</span></span><br><span class="line"><span class="string">        overlap: (float) The overlap thresh for suppressing unnecessary boxes.</span></span><br><span class="line"><span class="string">        top_k: (int) The Maximum number of box preds to consider.</span></span><br><span class="line"><span class="string">    Return:</span></span><br><span class="line"><span class="string">        The indices of the kept boxes with respect to num_priors.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    keep = scores.new(scores.size(<span class="number">0</span>)).zero_().long()</span><br><span class="line">    <span class="keyword">if</span> boxes.numel() == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> keep</span><br><span class="line">    x1 = boxes[:, <span class="number">0</span>]</span><br><span class="line">    y1 = boxes[:, <span class="number">1</span>]</span><br><span class="line">    x2 = boxes[:, <span class="number">2</span>]</span><br><span class="line">    y2 = boxes[:, <span class="number">3</span>]</span><br><span class="line">    area = torch.mul(x2 - x1, y2 - y1)</span><br><span class="line">    v, idx = scores.sort(<span class="number">0</span>)  <span class="comment"># sort in ascending order</span></span><br><span class="line">    <span class="comment"># I = I[v &gt;= 0.01]</span></span><br><span class="line">    idx = idx[-top_k:]  <span class="comment"># indices of the top-k largest vals</span></span><br><span class="line">    xx1 = boxes.new()</span><br><span class="line">    yy1 = boxes.new()</span><br><span class="line">    xx2 = boxes.new()</span><br><span class="line">    yy2 = boxes.new()</span><br><span class="line">    w = boxes.new()</span><br><span class="line">    h = boxes.new()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># keep = torch.Tensor()</span></span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> idx.numel() &gt; <span class="number">0</span>:</span><br><span class="line">        i = idx[<span class="number">-1</span>]  <span class="comment"># index of current largest val</span></span><br><span class="line">        <span class="comment"># keep.append(i)</span></span><br><span class="line">        keep[count] = i</span><br><span class="line">        count += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> idx.size(<span class="number">0</span>) == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        idx = idx[:<span class="number">-1</span>]  <span class="comment"># remove kept element from view</span></span><br><span class="line">        <span class="comment"># load bboxes of next highest vals</span></span><br><span class="line">        torch.index_select(x1, <span class="number">0</span>, idx, out=xx1)</span><br><span class="line">        torch.index_select(y1, <span class="number">0</span>, idx, out=yy1)</span><br><span class="line">        torch.index_select(x2, <span class="number">0</span>, idx, out=xx2)</span><br><span class="line">        torch.index_select(y2, <span class="number">0</span>, idx, out=yy2)</span><br><span class="line">        <span class="comment"># store element-wise max with next highest score</span></span><br><span class="line">        xx1 = torch.clamp(xx1, min=x1[i])</span><br><span class="line">        yy1 = torch.clamp(yy1, min=y1[i])</span><br><span class="line">        xx2 = torch.clamp(xx2, max=x2[i])</span><br><span class="line">        yy2 = torch.clamp(yy2, max=y2[i])</span><br><span class="line">        w.resize_as_(xx2)</span><br><span class="line">        h.resize_as_(yy2)</span><br><span class="line">        w = xx2 - xx1</span><br><span class="line">        h = yy2 - yy1</span><br><span class="line">        <span class="comment"># check sizes of xx1 and xx2.. after each iteration</span></span><br><span class="line">        w = torch.clamp(w, min=<span class="number">0.0</span>)</span><br><span class="line">        h = torch.clamp(h, min=<span class="number">0.0</span>)</span><br><span class="line">        inter = w*h</span><br><span class="line">        <span class="comment"># IoU = i / (area(a) + area(b) - i)</span></span><br><span class="line">        rem_areas = torch.index_select(area, <span class="number">0</span>, idx)  <span class="comment"># load remaining areas)</span></span><br><span class="line">        union = (rem_areas - inter) + area[i]</span><br><span class="line">        IoU = inter/union  <span class="comment"># store result in iou</span></span><br><span class="line">        <span class="comment"># keep only elements with an IoU &lt;= overlap</span></span><br><span class="line">        idx = idx[IoU.le(overlap)]</span><br><span class="line">    <span class="keyword">return</span> keep, count</span><br></pre></td></tr></table></figure>
<hr>
<p><a name="ac0465d6"></a></p>
<h3 id="构建-SSD-网络"><a href="#构建-SSD-网络" class="headerlink" title="构建 SSD 网络"></a>构建 SSD 网络</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SSD</span><span class="params">(nn.Module)</span>:</span> </span><br><span class="line">   	<span class="comment"># ...自定义SSD网络</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">vgg</span><span class="params">(cfg, i, batch_norm=False)</span>:</span></span><br><span class="line">    <span class="comment"># ... 搭建vgg网络</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_extras</span><span class="params">(cfg, i, batch_norm=False)</span>:</span></span><br><span class="line">    <span class="comment"># ... 向VGG网络中添加额外的层用于feature scaling</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">multibox</span><span class="params">(vgg, extra_layers, cfg, num_classes)</span>:</span></span><br><span class="line">    <span class="comment"># ... 构建multibox结构</span></span><br><span class="line">    </span><br><span class="line">base = &#123; <span class="comment"># vgg 网络结构参数</span></span><br><span class="line">    <span class="string">'300'</span>: [<span class="number">64</span>, <span class="number">64</span>, <span class="string">'M'</span>, <span class="number">128</span>, <span class="number">128</span>, <span class="string">'M'</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="string">'C'</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">'M'</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>],</span><br><span class="line">    <span class="string">'500'</span>: []</span><br><span class="line">&#125;</span><br><span class="line">extras = &#123; <span class="comment"># extras 层参数</span></span><br><span class="line">    <span class="string">'300'</span>: [<span class="number">256</span>, <span class="string">'S'</span>, <span class="number">512</span>, <span class="number">128</span>, <span class="string">'S'</span>, <span class="number">256</span>, <span class="number">128</span>, <span class="number">256</span>, <span class="number">128</span>, <span class="number">256</span>],</span><br><span class="line">    <span class="string">'500'</span>: []</span><br><span class="line">&#125;</span><br><span class="line">mbox = &#123; <span class="comment"># multibox 相关参数</span></span><br><span class="line">    <span class="string">'300'</span>: [<span class="number">4</span>, <span class="number">6</span>, <span class="number">6</span>, <span class="number">6</span>, <span class="number">4</span>, <span class="number">4</span>],</span><br><span class="line">    <span class="string">'500'</span>: []</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_ssd</span><span class="params">(phase, size=<span class="number">300</span>, num_classes=<span class="number">21</span>)</span>:</span></span><br><span class="line">    <span class="comment"># 构建模型函数, 调用上面的函数进行构建</span></span><br><span class="line">    <span class="keyword">if</span> phase != <span class="string">"test"</span> <span class="keyword">and</span> phase != <span class="string">"train"</span>: <span class="comment"># 只能是训练或者预测阶段</span></span><br><span class="line">        print(<span class="string">"ERROR: Phase: "</span> + phase + <span class="string">" not recognized"</span>)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    <span class="keyword">if</span> size != <span class="number">300</span>:</span><br><span class="line">        print(<span class="string">"ERROR: You specified size "</span> + repr(size) + <span class="string">". However, "</span>+</span><br><span class="line">                <span class="string">"currently only SSD300 is supported!"</span>) <span class="comment"># 仅仅支持300size的SSD</span></span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">      </span><br><span class="line">    base_, extras_, head_ = multibox(vgg(base[str(size)], <span class="number">3</span>),</span><br><span class="line">            add_extras(extras[str(size), <span class="number">1024</span>),</span><br><span class="line">            mbox[str(size)], num_classes )</span><br><span class="line">    <span class="keyword">return</span> SSD(phase, size, base_, extras_, head_, num_classes)</span><br></pre></td></tr></table></figure>
<hr>
<p><a name="2f24b902"></a></p>
<h3 id="损失函数-MultiBox"><a href="#损失函数-MultiBox" class="headerlink" title="损失函数 MultiBox"></a>损失函数 MultiBox</h3><p><img src="https://cdn.nlark.com/yuque/0/2019/png/220248/1552295800384-c456459f-42d5-4273-a65d-975b49fcc66c.png#align=left&amp;display=inline&amp;height=130&amp;name=image.png&amp;originHeight=163&amp;originWidth=603&amp;size=27643&amp;status=done&amp;width=482" alt="image.png"><br></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># layers/modules/multibox_loss.py</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MultiBoxLoss</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="comment"># 计算目标:</span></span><br><span class="line">    <span class="comment"># 输出那些与真实框的iou大于一定阈值的框的下标.</span></span><br><span class="line">    <span class="comment"># 根据与真实框的偏移量输出localization目标</span></span><br><span class="line">    <span class="comment"># 用难样例挖掘算法去除大量负样本(默认正负样本比例为1:3)</span></span><br><span class="line">    <span class="comment"># 目标损失:</span></span><br><span class="line">    <span class="comment"># L(x,c,l,g) = (Lconf(x,c) + αLloc(x,l,g)) / N</span></span><br><span class="line">    <span class="comment"># 参数:</span></span><br><span class="line">    <span class="comment"># c: 类别置信度(class confidences)</span></span><br><span class="line">    <span class="comment"># l: 预测的框(predicted boxes)</span></span><br><span class="line">    <span class="comment"># g: 真实框(ground truth boxes)</span></span><br><span class="line">    <span class="comment"># N: 匹配到的框的数量(number of matched default boxes)</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, num_classes, overlap_thresh, prior_for_matching, bkg_label, neg_mining, neg_pos, neg_overlap, encode_target, use_gpu=True)</span>:</span></span><br><span class="line">        super(MultiBoxLoss, self).__init__()</span><br><span class="line">        self.use_gpu = use_gpu</span><br><span class="line">        self.num_classes= num_classes <span class="comment"># 列表数</span></span><br><span class="line">        self.threshold = overlap_thresh <span class="comment"># 交并比阈值, 0.5</span></span><br><span class="line">        self.background_label = bkg_label <span class="comment"># 背景标签, 0</span></span><br><span class="line">        self.use_prior_for_matching = prior_for_matching <span class="comment"># True 没卵用</span></span><br><span class="line">        self.do_neg_mining = neg_mining <span class="comment"># True, 没卵用</span></span><br><span class="line">        self.negpos_ratio = neg_pos <span class="comment"># 负样本和正样本的比例, 3:1</span></span><br><span class="line">        self.neg_overlap = neg_overlap <span class="comment"># 0.5 判定负样本的阈值.</span></span><br><span class="line">        self.encode_target = encode_target <span class="comment"># False 没卵用</span></span><br><span class="line">        self.variance = cfg[<span class="string">"variance"</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, predictions, targets)</span>:</span></span><br><span class="line">        loc_data, conf_data, priors = predictions</span><br><span class="line">        <span class="comment"># loc_data: [batch_size, 8732, 4]</span></span><br><span class="line">        <span class="comment"># conf_data: [batch_size, 8732, 21]</span></span><br><span class="line">        <span class="comment"># priors: [8732, 4]  default box 对于任意的图片, 都是相同的, 因此无需带有 batch 维度</span></span><br><span class="line">        num = loc_data.size(<span class="number">0</span>) <span class="comment"># num = batch_size</span></span><br><span class="line">        priors = priors[:loc_data.size(<span class="number">1</span>), :] <span class="comment"># loc_data.size(1) = 8732, 因此 priors 维持不变</span></span><br><span class="line">        num_priors = (priors.size(<span class="number">0</span>)) <span class="comment"># num_priors = 8732</span></span><br><span class="line">        num_classes = self.num_classes <span class="comment"># num_classes = 21 (默认为voc数据集)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将priors(default boxes)和ground truth boxes匹配</span></span><br><span class="line">        loc_t = torch.Tensor(num, num_priors, <span class="number">4</span>) <span class="comment"># shape:[batch_size, 8732, 4]</span></span><br><span class="line">        conf_t = torch.LongTensor(num, num_priors) <span class="comment"># shape:[batch_size, 8732]</span></span><br><span class="line">        <span class="keyword">for</span> idx <span class="keyword">in</span> range(num):</span><br><span class="line">            <span class="comment"># targets是列表, 列表的长度为batch_size, 列表中每个元素为一个 tensor,</span></span><br><span class="line">            <span class="comment"># 其 shape 为 [num_objs, 5], 其中 num_objs 为当前图片中物体的数量, 第二维前4个元素为边框坐标, 最后一个元素为类别编号(1~20)</span></span><br><span class="line">            truths = targets[idx][:, :<span class="number">-1</span>].data <span class="comment"># [num_objs, 4]</span></span><br><span class="line">            labels = targets[idx][:, <span class="number">-1</span>].data <span class="comment"># [num_objs] 使用的是 -1, 而不是 -1:, 因此, 返回的维度变少了</span></span><br><span class="line">            defaults = priors.data <span class="comment"># [8732, 4]</span></span><br><span class="line">            <span class="comment"># from ..box_utils import match</span></span><br><span class="line">            <span class="comment"># 关键函数, 实现候选框与真实框之间的匹配, 注意是候选框而不是预测结果框! 这个函数实现较为复杂, 会在后面着重讲解</span></span><br><span class="line">            match(self.threshold, truths, defaults, self.variance, labels, loc_t, conf_t, idx) <span class="comment"># 注意! 要清楚 Python 中的参数传递机制, 此处在函数内部会改变 loc_t, conf_t 的值, 关于 match 的详细讲解可以看后面的代码解析</span></span><br><span class="line">        <span class="keyword">if</span> self.use_gpu:</span><br><span class="line">            loc_t = loc_t.cuda()</span><br><span class="line">            conf_t = conf_t.cuda()</span><br><span class="line">        <span class="comment"># 用Variable封装loc_t, 新版本的 PyTorch 无需这么做, 只需要将 requires_grad 属性设置为 True 就行了</span></span><br><span class="line">        loc_t = Variable(loc_t, requires_grad=<span class="literal">False</span>)</span><br><span class="line">        conf_t = Variable(conf_t, requires_grad=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">        pos = conf_t &gt; <span class="number">0</span> <span class="comment"># 筛选出 &gt;0 的box下标(大部分都是=0的)</span></span><br><span class="line">        num_pos = pos.sum(dim=<span class="number">1</span>, keepdim=<span class="literal">True</span>) <span class="comment"># 求和, 取得满足条件的box的数量, [batch_size, num_gt_threshold]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 位置(localization)损失函数, 使用 Smooth L1 函数求损失</span></span><br><span class="line">        <span class="comment"># loc_data:[batch, num_priors, 4]</span></span><br><span class="line">        <span class="comment"># pos: [batch, num_priors]</span></span><br><span class="line">        <span class="comment"># pos_idx: [batch, num_priors, 4], 复制下标成坐标格式, 以便获取坐标值</span></span><br><span class="line">        pos_idx = pos.unsqueeze(pos.dim()).expand_as(loc_data)</span><br><span class="line">        loc_p = loc_data[pos_idx].view(<span class="number">-1</span>, <span class="number">4</span>)<span class="comment"># 获取预测结果值</span></span><br><span class="line">        loc_t = loc_t[pos_idx].view(<span class="number">-1</span>, <span class="number">4</span>) <span class="comment"># 获取gt值</span></span><br><span class="line">        loss_l = F.smooth_l1_loss(loc_p, loc_t, size_average=<span class="literal">False</span>) <span class="comment"># 计算损失</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算最大的置信度, 以进行难负样本挖掘</span></span><br><span class="line">        <span class="comment"># conf_data: [batch, num_priors, num_classes]</span></span><br><span class="line">        <span class="comment"># batch_conf: [batch, num_priors, num_classes]</span></span><br><span class="line">        batch_conf = conf_data.view(<span class="number">-1</span>, self.num_classes) <span class="comment"># reshape</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># conf_t: [batch, num_priors]</span></span><br><span class="line">        <span class="comment"># loss_c: [batch*num_priors, 1], 计算每个priorbox预测后的损失</span></span><br><span class="line">        loss_c = log_sum_exp(batch_conf) - batch_conf.gather(<span class="number">1</span>, conf_t.view(<span class="number">-1</span>,<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 难负样本挖掘, 按照loss进行排序, 取loss最大的负样本参与更新</span></span><br><span class="line">        loss_c[pos.view(<span class="number">-1</span>, <span class="number">1</span>)] = <span class="number">0</span> <span class="comment"># 将所有的pos下标的box的loss置为0(pos指示的是正样本的下标)</span></span><br><span class="line">        <span class="comment"># 将 loss_c 的shape 从 [batch*num_priors, 1] 转换成 [batch, num_priors]</span></span><br><span class="line">        loss_c = loss_c.view(num, <span class="number">-1</span>) <span class="comment"># reshape</span></span><br><span class="line">        <span class="comment"># 进行降序排序, 并获取到排序的下标</span></span><br><span class="line">        _, loss_idx = loss_c.sort(<span class="number">1</span>, descending=<span class="literal">True</span>)</span><br><span class="line">        <span class="comment"># 将下标进行升序排序, 并获取到下标的下标</span></span><br><span class="line">        _, idx_rank = loss_idx.sort(<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># num_pos: [batch, 1], 统计每个样本中的obj个数</span></span><br><span class="line">        num_pos = pos.long().sum(<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">        <span class="comment"># 根据obj的个数, 确定负样本的个数(正样本的3倍)</span></span><br><span class="line">        num_neg = torch.clamp(self.negpos_ratio*num_pos, max=pos.size(<span class="number">1</span>)<span class="number">-1</span>)</span><br><span class="line">        <span class="comment"># 获取到负样本的下标</span></span><br><span class="line">        neg = idx_rank &lt; num_neg.expand_as(idx_rank)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算包括正样本和负样本的置信度损失</span></span><br><span class="line">        <span class="comment"># pos: [batch, num_priors]</span></span><br><span class="line">        <span class="comment"># pos_idx: [batch, num_priors, num_classes]</span></span><br><span class="line">        pos_idx = pos.unsqueeze(<span class="number">2</span>).expand_as(conf_data)</span><br><span class="line">        <span class="comment"># neg: [batch, num_priors]</span></span><br><span class="line">        <span class="comment"># neg_idx: [batch, num_priors, num_classes]</span></span><br><span class="line">        neg_idx = neg.unsqueeze(<span class="number">2</span>).expand_as(conf_data)</span><br><span class="line">        <span class="comment"># 按照pos_idx和neg_idx指示的下标筛选参与计算损失的预测数据</span></span><br><span class="line">        conf_p = conf_data[(pos_idx+neg_idx).gt(<span class="number">0</span>)].view(<span class="number">-1</span>, self.num_classes)</span><br><span class="line">        <span class="comment"># 按照pos_idx和neg_idx筛选目标数据</span></span><br><span class="line">        targets_weighted = conf_t[(pos+neg).gt(<span class="number">0</span>)]</span><br><span class="line">        <span class="comment"># 计算二者的交叉熵</span></span><br><span class="line">        loss_c = F.cross_entropy(conf_p, targets_weighted, size_average=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将损失函数归一化后返回</span></span><br><span class="line">        N = num_pos.data.sum()</span><br><span class="line">        loss_l = loss_l / N</span><br><span class="line">        loss_c = loss_c / N</span><br><span class="line">        <span class="keyword">return</span> loss_l, loss_c</span><br></pre></td></tr></table></figure>
<p><a name="575e41e1"></a></p>
<h4 id="GT-Box-与-Default-Box-的匹配"><a href="#GT-Box-与-Default-Box-的匹配" class="headerlink" title="GT Box 与 Default Box 的匹配"></a>GT Box 与 Default Box 的匹配</h4><p>在上面的代码中, 有一个很重要的函数, 即 match() 函数, 因为我们知道, 当根据特征图谱求出这些 prior box(default box, 8732个)以后, 我们仅仅知道这些 box 的 scale 和 aspect_ratios 信息, 但是如果要计算损失函数, 我们就必须知道与每个 prior box 相对应的 ground truth box 是哪一个, 因此, 我们需要根据交并比来求得这些 box 之间的匹配关系. 匹配算法的核心思想如下:</p>
<ol>
<li>首先将找到与每个 gtbox 交并比最高的 defaultbox, 记录其下标</li>
<li>然后找到与每个 defaultbox 交并比最高的 gtbox. 注意, 这两步不是一个相互的过程, 假想一种极端情况, 所有的priorbox与某个gtbox(标记为G)的交并比为1, 而其他gtbox分别有一个交并比最高的priorbox, 但是肯定小于1(因为其他的gtbox与G的交并比肯定小于1), 这样一来, 就会使得所有的priorbox都与G匹配.</li>
<li>为了防止上面的情况, 我们将那些对于gtbox来说, 交并比最高的priorbox, 强制进行互相匹配, 即令 best_truth_idx[best_prior_idx[j]] = j, 详细见下面的for循环.</li>
<li>根据下标获取每个priorbox对应的gtbox的坐标, 然后对坐标进行相应编码, 并存储起来, 同时将gt类别也存储起来, 到此, 匹配完成.</li>
</ol>
<p>（一）point_form() 函数 - 将 boxes 的坐标信息转换成左上角和右下角的形式<br>（二）intersect() 函数 - 返回 box_a 与 box_b 集合中元素的交集<br>（三）jaccard() 函数 - 返回 box_a 与 box_b 集合中元素的交并比<br>（四）encode() 函数 - 将 box 信息编码成小数形式, 方便网络训练<br>（五）match() 函数 - 匹配算法, 通过调用上述函数实现匹配功能</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ./layers/box_utils.py</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">point_form</span><span class="params">(boxes)</span>:</span></span><br><span class="line">    <span class="comment"># 将(cx, cy, w, h) 形式的box坐标转换成 (xmin, ymin, xmax, ymax) 形式</span></span><br><span class="line">    <span class="keyword">return</span> torch.cat( (boxes[:<span class="number">2</span>] - boxes[<span class="number">2</span>:]/<span class="number">2</span>), <span class="comment"># xmin, ymin</span></span><br><span class="line">                    (boxes[:<span class="number">2</span>] + boxes[<span class="number">2</span>:]/<span class="number">2</span>), <span class="number">1</span>) <span class="comment"># xmax, ymax</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">intersect</span><span class="params">(box_a, box_b)</span>:</span></span><br><span class="line">    <span class="comment"># box_a: (truths), (tensor:[num_obj, 4])</span></span><br><span class="line">    <span class="comment"># box_b: (priors), (tensor:[num_priors, 4], 即[8732, 4])</span></span><br><span class="line">    <span class="comment"># return: (tensor:[num_obj, num_priors]) box_a 与 box_b 两个集合中任意两个 box 的交集, 其中res[i][j]代表box_a中第i个box与box_b中第j个box的交集.(非对称矩阵)</span></span><br><span class="line">    <span class="comment"># 思路: 先将两个box的维度扩展至相同维度: [num_obj, num_priors, 4], 然后计算面积的交集</span></span><br><span class="line">    <span class="comment"># 两个box的交集可以看成是一个新的box, 该box的左上角坐标是box_a和box_b左上角坐标的较大值, 右下角坐标是box_a和box_b的右下角坐标的较小值</span></span><br><span class="line">    A = box_a.size(<span class="number">0</span>)</span><br><span class="line">    B = box_b.size(<span class="number">0</span>)</span><br><span class="line">    <span class="comment"># box_a 左上角/右下角坐标 expand以后, 维度会变成(A,B,2), 其中, 具体可看 expand 的相关原理. box_b也是同理, 这样做是为了得到a中某个box与b中某个box的左上角(min_xy)的较大者(max)</span></span><br><span class="line">    <span class="comment"># unsqueeze 为增加维度的数量, expand 为扩展维度的大小</span></span><br><span class="line">    min_xy = torch.max(box_a[:, :<span class="number">2</span>].unsqueeze(<span class="number">1</span>).expand(A,B,<span class="number">2</span>),</span><br><span class="line">                        box_b[:, :<span class="number">2</span>].unsqueeze(<span class="number">0</span>).expand(A,B,<span class="number">2</span>)) <span class="comment"># 在box_a的 A 和 2 之间增加一个维度, 并将维度扩展到 B. box_b 同理</span></span><br><span class="line">    <span class="comment"># 求右下角(max_xy)的较小者(min)</span></span><br><span class="line">    max_xy = torch.min(box_a[:, <span class="number">2</span>:].unsqueeze(<span class="number">1</span>).expand(A,B,<span class="number">2</span>),</span><br><span class="line">                        box_b[:, <span class="number">2</span>:].unsqueeze(<span class="number">0</span>).expand(A,B,<span class="number">2</span>))</span><br><span class="line">    inter = torch.clamp((max_xy, min_xy), min=<span class="number">0</span>) <span class="comment"># 右下角减去左上角, 如果为负值, 说明没有交集, 置为0</span></span><br><span class="line">    <span class="keyword">return</span> inter[:, :, <span class="number">0</span>] * inter[:, :, <span class="number">0</span>] <span class="comment"># 高×宽, 返回交集的面积, shape 刚好为 [A, B]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">jaccard</span><span class="params">(box_a, box_b)</span>:</span></span><br><span class="line">    <span class="comment"># A ∩ B / A ∪ B = A ∩ B / (area(A) + area(B) - A ∩ B)</span></span><br><span class="line">    <span class="comment"># box_a: (truths), (tensor:[num_obj, 4])</span></span><br><span class="line">    <span class="comment"># box_b: (priors), (tensor:[num_priors, 4], 即[8732, 4])</span></span><br><span class="line">    <span class="comment"># return: (tensor:[num_obj, num_priors]), 代表了 box_a 和 box_b 两个集合中任意两个 box之间的交并比</span></span><br><span class="line">    inter = intersect(box_a, box_b) <span class="comment"># 求任意两个box的交集面积, shape为[A, B], 即[num_obj, num_priors]</span></span><br><span class="line">    area_a = ((box_a[:,<span class="number">2</span>]-box_a[:,<span class="number">0</span>]) * (box_a[:,<span class="number">3</span>]-box_a[:,<span class="number">1</span>])).unsqueeze(<span class="number">1</span>).expand_as(inter) <span class="comment"># [A,B]</span></span><br><span class="line">    area_b = ((box_b[:,<span class="number">2</span>]-box_b[:,<span class="number">0</span>]) * (box_b[:,<span class="number">3</span>]-box_b[:,<span class="number">1</span>])).unsqueeze(<span class="number">0</span>).expand_as(inter) <span class="comment"># [A,B], 这里会将A中的元素复制B次</span></span><br><span class="line">    union = area_a + area_b - inter</span><br><span class="line">    <span class="keyword">return</span> inter / union <span class="comment"># [A, B], 返回任意两个box之间的交并比, res[i][j] 代表box_a中的第i个box与box_b中的第j个box之间的交并比.</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">encode</span><span class="params">(matched, priors, variances)</span>:</span></span><br><span class="line">    <span class="comment"># 对边框坐标进行编码, 需要宽度方差和高度方差两个参数, 具体公式可以参见原文公式(2)</span></span><br><span class="line">    <span class="comment"># matched: [num_priors,4] 存储的是与priorbox匹配的gtbox的坐标. 形式为(xmin, ymin, xmax, ymax)</span></span><br><span class="line">    <span class="comment"># priors: [num_priors, 4] 存储的是priorbox的坐标. 形式为(cx, cy, w, h)</span></span><br><span class="line">    <span class="comment"># return : encoded boxes: [num_priors, 4]</span></span><br><span class="line">    g_cxy = (matched[:, :<span class="number">2</span>] + matched[:, <span class="number">2</span>:])/<span class="number">2</span> - priors[:, :<span class="number">2</span>] <span class="comment"># 用互相匹配的gtbox的中心坐标减去priorbox的中心坐标, 获得中心坐标的偏移量</span></span><br><span class="line">    g_cxy /= (variances[<span class="number">0</span>]*priors[:, <span class="number">2</span>:]) <span class="comment"># 令中心坐标分别除以 d_i^w 和 d_i^h, 正如原文公式所示</span></span><br><span class="line">    <span class="comment">#variances[0]为0.1, 令其分别乘以w和h, 得到d_i^w 和 d_i^h</span></span><br><span class="line">    g_wh = (matched[:, <span class="number">2</span>:] - matched[:, :<span class="number">2</span>]) / priors[:, <span class="number">2</span>:] <span class="comment"># 令互相匹配的gtbox的宽高除以priorbox的宽高.</span></span><br><span class="line">    g_wh = torch.log(g_wh) / variances[<span class="number">1</span>] <span class="comment"># 这里这个variances[1]=0.2 不太懂是为什么.</span></span><br><span class="line">    <span class="keyword">return</span> torch.cat([g_cxy, g_wh], <span class="number">1</span>) <span class="comment"># 将编码后的中心坐标和宽高``连接起来, 返回 [num_priors, 4]</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">match</span><span class="params">(threshold, truths, priors, variances, labels, loc_t, conf_t, idx)</span>:</span></span><br><span class="line">    <span class="comment"># threshold: (float) 确定是否匹配的交并比阈值</span></span><br><span class="line">    <span class="comment"># truths: (tensor: [num_obj, 4]) 存储真实 box 的边框坐标</span></span><br><span class="line">    <span class="comment"># priors: (tensor: [num_priors, 4], 即[8732, 4]), 存储推荐框的坐标, 注意, 此时的框是 default box, 而不是 SSD 网络预测出来的框的坐标, 预测的结果存储在 loc_data中, 其 shape 为[num_obj, 8732, 4].</span></span><br><span class="line">    <span class="comment"># variances: cfg['variance'], [0.1, 0.2], 用于将坐标转换成方便训练的形式(参考RCNN系列对边框坐标的处理)</span></span><br><span class="line">    <span class="comment"># labels: (tensor: [num_obj]), 代表了每个真实 box 对应的类别的编号</span></span><br><span class="line">    <span class="comment"># loc_t: (tensor: [batches, 8732, 4]),</span></span><br><span class="line">    <span class="comment"># conf_t: (tensor: [batches, 8732]),</span></span><br><span class="line">    <span class="comment"># idx: batches 中图片的序号, 标识当前正在处理的 image 在 batches 中的序号</span></span><br><span class="line">    overlaps = jaccard(truths, point_form(priors)) <span class="comment"># [A, B], 返回任意两个box之间的交并比, overlaps[i][j] 代表box_a中的第i个box与box_b中的第j个box之间的交并比.</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 二部图匹配(Bipartite Matching)</span></span><br><span class="line">    <span class="comment"># [num_objs,1], 得到对于每个 gt box 来说的匹配度最高的 prior box, 前者存储交并比, 后者存储prior box在num_priors中的位置</span></span><br><span class="line">    best_prior_overlap, best_prior_idx = overlaps.max(<span class="number">1</span>, keepdim=<span class="literal">True</span>) <span class="comment"># keepdim=True, 因此shape为[num_objs,1]</span></span><br><span class="line">    <span class="comment"># [1, num_priors], 即[1,8732], 同理, 得到对于每个 prior box 来说的匹配度最高的 gt box</span></span><br><span class="line">    best_truth_overlap, best_truth_idx = overlaps.max(<span class="number">0</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">    best_prior_idx.squeeze_(<span class="number">1</span>) <span class="comment"># 上面特意保留了维度(keepdim=True), 这里又都把维度 squeeze/reduce 了, 实际上只需用默认的 keepdim=False 就可以自动 squeeze/reduce 维度.</span></span><br><span class="line">    best_prior_overlap.squeeze_(<span class="number">1</span>)</span><br><span class="line">    best_truth_idx.squeeze_(<span class="number">0</span>)</span><br><span class="line">    best_truth_overlap.squeeze_(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    best_truth_overlap.index_fill_(<span class="number">0</span>, best_prior_idx, <span class="number">2</span>)</span><br><span class="line">    <span class="comment"># 维度压缩后变为[num_priors], best_prior_idx 维度为[num_objs],</span></span><br><span class="line">    <span class="comment"># 该语句会将与gt box匹配度最好的prior box 的交并比置为 2, 确保其最大, 以免防止某些 gtbox 没有匹配的 priorbox.</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 假想一种极端情况, 所有的priorbox与某个gtbox(标记为G)的交并比为1, 而其他gtbox分别有一个交并比</span></span><br><span class="line">    <span class="comment"># 最高的priorbox, 但是肯定小于1(因为其他的gtbox与G的交并比肯定小于1), 这样一来, 就会使得所有</span></span><br><span class="line">    <span class="comment"># 的priorbox都与G匹配, 为了防止这种情况, 我们将那些对gtbox来说, 具有最高交并比的priorbox,</span></span><br><span class="line">    <span class="comment"># 强制进行互相匹配, 即令best_truth_idx[best_prior_idx[j]] = j, 详细见下面的for循环</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 注意!!: 因为 gt box 的数量要远远少于 prior box 的数量, 因此, 同一个 gt box 会与多个 prior box 匹配.</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(best_prior_idx.size(<span class="number">0</span>)): <span class="comment"># range:0~num_obj-1</span></span><br><span class="line">        best_truth_idx[best_prior_idx[j]] = j</span><br><span class="line">        <span class="comment"># best_prior_idx[j] 代表与box_a的第j个box交并比最高的 prior box 的下标, 将与该 gtbox</span></span><br><span class="line">        <span class="comment"># 匹配度最好的 prior box 的下标改为j, 由此,完成了该 gtbox 与第j个 prior box 的匹配.</span></span><br><span class="line">        <span class="comment"># 这里的循环只会进行num_obj次, 剩余的匹配为 best_truth_idx 中原本的值.</span></span><br><span class="line">        <span class="comment"># 这里处理的情况是, priorbox中第i个box与gtbox中第k个box的交并比最高,</span></span><br><span class="line">        <span class="comment"># 即 best_truth_idx[i]= k</span></span><br><span class="line">        <span class="comment"># 但是对于best_prior_idx[k]来说, 它却与priorbox的第l个box有着最高的交并比,</span></span><br><span class="line">        <span class="comment"># 即best_prior_idx[k]=l</span></span><br><span class="line">        <span class="comment"># 而对于gtbox的另一个边框gtbox[j]来说, 它与priorbox[i]的交并比最大,</span></span><br><span class="line">        <span class="comment"># 即但是对于best_prior_idx[j] = i.</span></span><br><span class="line">        <span class="comment"># 那么, 此时, 我们就应该将best_truth_idx[i]= k 修改成 best_truth_idx[i]= j.</span></span><br><span class="line">        <span class="comment"># 即令 priorbox[i] 与 gtbox[j]对应.</span></span><br><span class="line">        <span class="comment"># 这样做的原因: 防止某个gtbox没有匹配的 prior box.</span></span><br><span class="line">    mathes = truths[best_truth_idx]</span><br><span class="line">    <span class="comment"># truths 的shape 为[num_objs, 4], 而best_truth_idx是一个指示下标的列表, 列表长度为 8732,</span></span><br><span class="line">    <span class="comment"># 列表中的下标范围为0~num_objs-1, 代表的是与每个priorbox匹配的gtbox的下标</span></span><br><span class="line">    <span class="comment"># 上面的表达式会返回一个shape为 [num_priors, 4], 即 [8732, 4] 的tensor, 代表的就是与每个priorbox匹配的gtbox的坐标值.</span></span><br><span class="line">    conf = labels[best_truth_idx]+<span class="number">1</span> <span class="comment"># 与上面的语句道理差不多, 这里得到的是每个prior box匹配的类别编号, shape 为[8732]</span></span><br><span class="line">    conf[best_truth_overlap &lt; threshold] = <span class="number">0</span> <span class="comment"># 将与gtbox的交并比小于阈值的置为0 , 即认为是非物体框</span></span><br><span class="line">    loc = encode(matches, priors, variances) <span class="comment"># 返回编码后的中心坐标和宽高.</span></span><br><span class="line">    loc_t[idx] = loc <span class="comment"># 设置第idx张图片的gt编码坐标信息</span></span><br><span class="line">    conf_t[idx] = conf <span class="comment"># 设置第idx张图片的编号信息.(大于0即为物体编号, 认为有物体, 小于0认为是背景)</span></span><br></pre></td></tr></table></figure>
<hr>
<p><a name="d8b16075"></a></p>
<h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><p><a name="cd8992b6"></a></p>
<h3 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h3><p><a name="Tricks"></a></p>
<h3 id="Tricks"><a href="#Tricks" class="headerlink" title="Tricks"></a>Tricks</h3>
      
    </div>
    
    
    

    

    

    
    <div>
    
    <div>  <div style="text-align:center;color: #ccc;font-size:14px;">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div>  </div>


    
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/pytorch/" rel="tag"><i class="fa fa-tag"></i> pytorch</a>
          
            <a href="/tags/One-Stage/" rel="tag"><i class="fa fa-tag"></i> One Stage</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/经典网络结构/VGG 实现/" rel="next" title="AlexNet 实现">
                <i class="fa fa-chevron-left"></i> AlexNet 实现
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/经典网络结构/ResNet/" rel="prev" title="ResNet">
                ResNet <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
      <div id="sidebar-dimmer"></div>
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      
      
      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/cjh_head_yuque.png" alt="Jiahao Chen">
            
              <p class="site-author-name" itemprop="name">Jiahao Chen</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>
          
          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">20</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">9</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">10</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>
          <iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=586299&auto=1&height=66"></iframe>
          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/Edison0902" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:edison.18whu@gmail.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://weibo.com/u/6176093611" target="_blank" title="Weibo">
                      
                        <i class="fa fa-fw fa-globe"></i>Weibo</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://plus.google.com/yourname" target="_blank" title="Google">
                      
                        <i class="fa fa-fw fa-google"></i>Google</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://twitter.com/yourname" target="_blank" title="Twitter">
                      
                        <i class="fa fa-fw fa-twitter"></i>Twitter</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://www.facebook.com/yourname" target="_blank" title="FB Page">
                      
                        <i class="fa fa-fw fa-facebook"></i>FB Page</a>
                  </span>
                
            </div>
          

          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-inline">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                Links
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="http://baidu.com/" title="百度" target="_blank">百度</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="http://google.com/" title="谷歌" target="_blank">谷歌</a>
                  </li>
                
              </ul>
            </div>
          

          

        </div>
      </section>
      
      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#SSD-目标检测算法"><span class="nav-text">SSD 目标检测算法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#基础知识"><span class="nav-text">基础知识</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#代码结构详解"><span class="nav-text">代码结构详解</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#vgg-修改后的-VGG-16"><span class="nav-text">vgg() - 修改后的 VGG-16</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#add-extras-添加层，作用：回归、分类"><span class="nav-text">add_extras() - 添加层，作用：回归、分类</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#multibox-定义坐标预测层、分类层"><span class="nav-text">multibox() - 定义坐标预测层、分类层</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#SSD-网络定义"><span class="nav-text">SSD 网络定义</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#（一）PriorBox-类-用于生成-Default-box"><span class="nav-text">（一）PriorBox 类 - 用于生成 Default box</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#（二）L2Norm-类-实现了-L2归一化"><span class="nav-text">（二）L2Norm 类 - 实现了 L2归一化</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#（三）Detect-类-用于解析预测结果-并将其转换成边框坐标和类别编号"><span class="nav-text">（三）Detect 类 - 用于解析预测结果, 并将其转换成边框坐标和类别编号</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#decode-和-nms-函数"><span class="nav-text">decode() 和 nms() 函数</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#构建-SSD-网络"><span class="nav-text">构建 SSD 网络</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#损失函数-MultiBox"><span class="nav-text">损失函数 MultiBox</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#GT-Box-与-Default-Box-的匹配"><span class="nav-text">GT Box 与 Default Box 的匹配</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#训练"><span class="nav-text">训练</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#验证"><span class="nav-text">验证</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Tricks"><span class="nav-text">Tricks</span></a></li></ol></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

      
        <div class="back-to-top">
          <i class="fa fa-arrow-up"></i>
          
            <span id="scrollpercent"><span>0</span>%</span>
          
        </div>
      


    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2018 &mdash; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-[object Object]"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">陈家豪</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>








        







        
      </div>
    </footer>

    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  

  

  

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"model":{"jsonPath":"/live2dw/assets/miku.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":false},"log":false});</script></body>
</html>



<!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/src/clicklove.js"></script>